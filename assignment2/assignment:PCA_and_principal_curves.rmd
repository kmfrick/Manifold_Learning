---
title: 'Assignment: PCA and principal curves'
author: "Kevin Frick, Patrick Lutz, and Sonia Petrini"
date: "11/17/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Assignment: PCA and principal curves

## Part1: PCA

Reading the data:
```{r}
library(dplyr)
zip.train <- read.table("zip.train")
zeros <- filter(zip.train, V1==0)
zeros <- zeros
```

a. Do a hierarchical clustering of these data using the ward.D method, plot the resulting dendogram and cut it into k=4 clusters
```{r}
dendo <- hclust(dist(zeros), method="ward.D")
plot(dendo)
dendo.4 <- cutree(dendo,4)
```

b. Plot the average digit at each cluster.
```{r}
plot.zip <- function(x,use.first=FALSE, main=NULL){
  x<-as.numeric(x)
  if (use.first){
    x.mat <- matrix(x,16,16)
  }else{
    x.mat <- matrix(x[-1],16,16)
  }
  image(1:16,1:16,x.mat[,16:1],
        col=gray(seq(1,0,l=12)))
  if (!is.null(main)) title(main)
  else if (!use.first) title(x[1])
  
  #col=gray(seq(1,0,l=2)))
}
for (i in 1:4) {
  plot.zip(colMeans(zeros[which(dendo.4==i),]), main = paste("Cluster", i))
}

```

c. Compute the principal components for this data set. Plot the scatterplot of the scores in the first two PCs, using a different color for points in different clusters.
```{r}
zip_pc <- princomp(zeros)
for (i in 1:5) {
  pts_in_cluster <- which(dendo.4==i)
  pc_scores <- zip_pc$scores[pts_in_cluster,1:2]
  xmin <- min(zip_pc$scores[,1])
  xmax <- max(zip_pc$scores[,1])
  ymin <- min(zip_pc$scores[,2])
  ymax <- max(zip_pc$scores[,2])

  if (i == 1) plot(pc_scores, col=i, xlim=c(xmin, xmax), ylim=c(ymin,ymax))
  else points(pc_scores, col=i)
}
```

d. For each one of the k clusters obtained above, do the following tasks: (A unique plot should be done, at which the k densities are represented simultaneously)
 - Consider the bivariate data set of the scores in PC1 and PC2 of the points in this cluster. 
 - Estimate non-parametrically the joint density of (PC1,PC2), conditional to this cluster. Use the default bandwith values. 
 - Represent the estimated bivariate density using the level curve that covers the 75% of the points in this cluster.
```{r}
library(sm)
options(error = function() traceback(10))

for (i in 1:5) {
  pts_in_cluster <- which(dendo.4==i)
  pc_scores <- zip_pc$scores[pts_in_cluster,1:2]
  xmin <- min(zip_pc$scores[,1])
  xmax <- max(zip_pc$scores[,1])
  ymin <- min(zip_pc$scores[,2])
  ymax <- max(zip_pc$scores[,2])

  if (i == 1) plot(pc_scores, col=i, xlim=c(xmin, xmax), ylim=c(ymin,ymax))
  else points(pc_scores, col=i)
  sm.density(pc_scores, col=i, display="slice", add=TRUE, props=c(75))
}

```

e. Over the previous plot, represent the principal curve obtained from the 256-dimensional set of zeros using the package princurve.
```{r}
library(princurve)
options(error = function() traceback(10))
xmin <- min(zip_pc$scores[,1])
xmax <- max(zip_pc$scores[,1])
ymin <- min(zip_pc$scores[,2])
ymax <- max(zip_pc$scores[,2])

options(error = function() traceback(10))
pc <- principal_curve(as.matrix(zeros), df=15)
points_to_pc <- predict(zip_pc, pc$s)
for (i in 1:5) {
  pts_in_cluster <- which(dendo.4==i)
  pc_scores <- zip_pc$scores[pts_in_cluster,1:2]
  if (i == 1) plot(pc_scores, col=i, xlim=c(xmin, xmax), ylim=c(ymin,ymax))
  else points(pc_scores, col=i)
}

lines(points_to_pc[pc$ord,1:2],col=6,lwd=2)
```

f. For each one of the k clusters obtained above, do the following tasks: (A unique scatter plot of the scores in PC1 and PC2 should be done, over which the k densities are represented simultaneously) 
 - Consider the univariate data set of the lambda scores over the principal curve of the points in this cluster. 
 - Estimate non-parametrically the density function of lambda, conditional to this cluster. Use the default bandwith value. 
 - Plot the estimated density function. 
```{r}
options(error = function() traceback(10))
xmin <- min(zip_pc$scores[,1])
xmax <- max(zip_pc$scores[,1])
ymin <- min(zip_pc$scores[,2])
ymax <- max(zip_pc$scores[,2])

options(error = function() traceback(10))

for (i in 1:5) {
  pts_in_cluster <- which(dendo.4==i)
  pc_scores <- zip_pc$scores[pts_in_cluster,1:2]
  if (i == 1) {
  sm.density(pc$lambda[pts_in_cluster], col=i, sm=75, xlab="Lambda")
} else {
    sm.density(pc$lambda[pts_in_cluster], col=i, add=TRUE, sm=75)

}

}


```



## Part2: Principal Curves

Get the data
```{r}
t <- seq(-1.5*pi,1.5*pi,l=100)
R<- 1
n<-75
sd.eps <- .15
set.seed(1)
y <- R*sign(t) - R*sign(t)*cos(t/R)
x <- -R*sin(t/R)
z <- (y/(2*R))^2
rt <- sort(runif(n)*3*pi - 1.5*pi)
eps <- rnorm(n)*sd.eps
ry <- R*sign(rt) - (R+eps)*sign(rt)*cos(rt/R)
rx <- -(R+eps)*sin(rt/R)
rz <- (ry/(2*R))^2 + runif(n,min=-2*sd.eps,max=2*sd.eps)
XYZ <- cbind(rx,ry,rz)
require(plot3D)
lines3D(x,y,z,colvar = NULL,
         phi = 20, theta = 60, r =sqrt(3), d =3, scale=FALSE,
         col=2,lwd=4,as=1,
         xlim=range(rx),ylim=range(ry),zlim=range(rz))
points3D(rx,ry,rz,col=4,pch=19,cex=.6,add=TRUE)
```


a. Choose the value of the degrees of freedom df by leave-one-out cross-validation. Restrict the search of df to seq(2,8,by=1). 

```{r}
sample <- sample.int(n = nrow(XYZ), size = floor(.75*nrow(XYZ)), replace = F)
train <- XYZ[sample, ]
test  <- XYZ[-sample, ]

# LOOCV to find best df
require(princurve)
dfs <- seq(2,8,by=1)
n_points <- nrow(XYZ)
distances <- c()

for (df in dfs){
  dist <- c()
  for(i in 1:n_points){
      validation <- t(as.matrix(XYZ[i,]))
      training <- XYZ[-i,]    
      fit <- principal_curve(training,df=df)
      proj <- project_to_curve(validation,fit$s)
      dist[i] <- proj$dist
  }
  distances <- append(distances,mean(dist))
}


# plot of LOOCV results
df_opt_dist <- min(distances)
df_opt <- dfs[which(distances==df_opt_dist)]
plot(x=dfs,y=distances,ylab="Total Squared Porojecting Distance",xlab="Degrees of Freedom",main="")
abline(h=df_opt_dist,lty="dashed",col="red")
```


b. Give a graphical representation of the principal curve output for the optimal df and comment on the obtained results.

The best value of Degrees of Freedom according to Leave-One-Out CV is 6. As we can see from the figure below, this value allows the Principal Curve to cross the data points while preserving its smoothness: it allows for some bias, but it gets complex enough to grasp the shape of the data. The Principal Curve created with df = 6 does a much better job at approximating the data distribution compared to the lower df value considered, namely 2. Indeed, the model built with this last value clearly leads to underfitting, and a very high total squared projection distance.

```{r}
par(mfrow=c(1,2))

# Principal Curve with lowest df
fit <- principal_curve(XYZ,df=dfs[1])
plot(fit,xlim=range(XYZ[,1]),ylim=range(XYZ[,2]),asp=1,main="Principal Curve with df=2",cex.main=1)
points(XYZ,col=4)
lines(fit)
points(fit)
whiskers(XYZ, fit$s)

# Principal Curve with best df
fit <- principal_curve(XYZ,df=df_opt)
plot(fit,xlim=range(XYZ[,1]),ylim=range(XYZ[,2]),asp=1,main=paste("Principal Curve with optimal df =",df_opt),cex.main=1)
points(XYZ,col=4)
lines(fit)
points(fit)
whiskers(XYZ, fit$s)

```




c. Compute the leave-one-out cross-validation for df=50 and compare it with the result corresponding to the optimal df value you found before.

By performing LOOCV with df = 50, we find a total squared distance equal to 0.0394, which increases by approximately 60 % the performance of the model, compared to the value found with 6, the optimal Degrees of Freedom.

```{r}
# LOOCV for df = 50
df <- 50
df50_distances <- c()
for(i in 1:n_points){
      validation <- t(as.matrix(XYZ[i,]))
      training <- XYZ[-i,]    
      fit <- principal_curve(training,df=df)
      proj <- project_to_curve(validation,fit$s)
      df50_distances[i] <- proj$dist
}
df50_dist <- mean(df50_distances)
print(paste("LOOCV score for df = 50:", df50_dist))
print(paste("LOOCV score for df =",df_opt,":",df_opt_dist))
change <- round((df_opt_dist-df50_dist)/df_opt_dist,3)
print(paste("Change in performance with new df = 50:",change*100, "%"))
```

  - Before fitting the principal curve with df=50 and based only on the leave-one-out cross-validation values, what value for df do you think that is better, the previous optimal one or df=50?

  Setting df = 50 allows one to reduce the projection distance of the points from the curve by more than 60 %. However, this is expected, as increasing this parameter results in a tighter fit of the model, and thus to a decrease in error. As already mentioned, the optimal df value seems to be a very good option to balance the model's bias and variability, as it is quite complex but allows for some error. Given this consideration, largely increasing the Degrees of Freedom will certainly lead to overfit the data, building a Principal Curve that tries to traverse all the points, but will not be able to generalize.

- Fit now the principal curve with df=50 and plot the fitted curve in the 3D scatterplot of the original points.

```{r}
fit <- principal_curve(XYZ,df=50)
princ_curve <- fit$s
lines3D(princ_curve[,1],princ_curve[,2],princ_curve[,3],colvar = NULL,
         phi = 20, theta = 60, r =sqrt(3), d =3, scale=FALSE,
         col=2,lwd=3,as=1,
         xlim=range(rx),ylim=range(ry),zlim=range(rz))
points3D(rx,ry,rz,col=4,pch=19,cex=.6,add=TRUE)
```


- Now, what value of df do you prefer?

From the visualization of the Principal Curve built with df = 50, we can confirm our expectation: this high df value leads to overfitting the data, creating a very complex and not smooth curve.

- The overfitting with df=50 is clear. Nevertheless leave-one-out cross-validation has not been able to
detect this fact. Why do you think that df=50 is given a so good value of leave-one-out cross-validation?

LOOCV is an unbiased measure that only takes into account the model's ability to give accurate predictions, but it does not stricly measure overfitting. In order to assess the level of overfitting, a measure considering both the model's error and complexity should be used, such as the AIC in regression. Train/Test splits or k-fold cross-validation would not be adequate either, since they are simply biased estimates of LOOCV. 







